{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Анализ текстов на слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import pymorphy3\n",
    "from functools import lru_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>tag</th>\n",
       "      <th>value</th>\n",
       "      <th>pstv</th>\n",
       "      <th>ngtv</th>\n",
       "      <th>neut</th>\n",
       "      <th>dunno</th>\n",
       "      <th>pstvNgtvDisagreementRatio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>абажур</td>\n",
       "      <td>NEUT</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>аббатство</td>\n",
       "      <td>NEUT</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.578</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>аббревиатура</td>\n",
       "      <td>NEUT</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.630</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>абзац</td>\n",
       "      <td>NEUT</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.706</td>\n",
       "      <td>0.157</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>абиссинец</td>\n",
       "      <td>NEUT</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0.491</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           term   tag  value   pstv   ngtv   neut  dunno  \\\n",
       "0        абажур  NEUT   0.08  0.185  0.037  0.580  0.198   \n",
       "1     аббатство  NEUT   0.10  0.192  0.038  0.578  0.192   \n",
       "2  аббревиатура  NEUT   0.08  0.196  0.000  0.630  0.174   \n",
       "3         абзац  NEUT   0.00  0.137  0.000  0.706  0.157   \n",
       "4     абиссинец  NEUT   0.28  0.151  0.113  0.245  0.491   \n",
       "\n",
       "   pstvNgtvDisagreementRatio  \n",
       "0                       0.00  \n",
       "1                       0.00  \n",
       "2                       0.00  \n",
       "3                       0.00  \n",
       "4                       0.19  "
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"/Users/a.chervonikov/Desktop/Purify/Purify/purify_ml/data/raw/kartaslovsent.csv\", sep=\";\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер словаря: 46127\n",
      "Пример записи: ('абажур', 'NEUT')\n",
      "Слово 'хороший' имеет метку: PSTV\n"
     ]
    }
   ],
   "source": [
    "term_to_tag_dict = dict(zip(dataset['term'], dataset['tag']))\n",
    "\n",
    "print(\"Размер словаря:\", len(term_to_tag_dict))\n",
    "print(\"Пример записи:\", list(term_to_tag_dict.items())[0])\n",
    "\n",
    "test_word = \"хороший\"\n",
    "if test_word in term_to_tag_dict:\n",
    "    print(f\"Слово '{test_word}' имеет метку: {term_to_tag_dict[test_word]}\")\n",
    "else:\n",
    "    print(f\"Слово '{test_word}' отсутствует в словаре\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Регулярка на мат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_regex = r\"\"\"(?iux)(?<![а-яё])(?:\n",
    "(?:(?:у|[нз]а|(?:хитро|не)?вз?[ыьъ]|с[ьъ]|(?:и|ра)[зс]ъ?|(?:о[тб]|п[оа]д)[ьъ]?|(?:\\S(?=[а-яё]))+?[оаеи-])-?)?(?:\n",
    "  [её](?:б(?!о[рй]|рач)|п[уа](?:ц|тс))|\n",
    "  и[пб][ае][тцд][ьъ]\n",
    ").*?|\n",
    "\n",
    "(?:(?:н[иеа]|(?:ра|и)[зс]|[зд]?[ао](?:т|дн[оа])?|с(?:м[еи])?|а[пб]ч|в[ъы]?|пр[еи])-?)?ху(?:[яйиеёю]|л+и(?!ган)).*?|\n",
    "\n",
    "бл(?:[эя]|еа?)(?:[дт][ьъ]?)?|\n",
    "\n",
    "\\S*?(?:\n",
    "  п(?:\n",
    "    [иеё]зд|\n",
    "    ид[аое]?р|\n",
    "    ед(?:р(?!о)|[аое]р|ик)|\n",
    "    охую\n",
    "  )|\n",
    "  бля(?:[дбц]|тс)|\n",
    "  [ое]ху[яйиеё]|\n",
    "  хуйн\n",
    ").*?|\n",
    "\n",
    "(?:о[тб]?|про|на|вы)?м(?:\n",
    "  анд(?:[ауеыи](?:л(?:и[сзщ])?[ауеиы])?|ой|[ао]в.*?|юк(?:ов|[ауи])?|е[нт]ь|ища)|\n",
    "  уд(?:[яаиое].+?|е?н(?:[ьюия]|ей))|\n",
    "  [ао]л[ао]ф[ьъ](?:[яиюе]|[еёо]й)\n",
    ")|\n",
    "\n",
    "елд[ауые].*?|\n",
    "ля[тд]ь|\n",
    "(?:[нз]а|по)х\n",
    ")(?![а-яё])\"\"\"\n",
    "\n",
    "PRONOUNS = ['я', 'ты', 'вы', 'он', 'она', 'оно', 'мы', 'они', 'вас', 'нас', 'их', 'его', 'её']\n",
    "stopword_set = set(nltk.corpus.stopwords.words('russian'))\n",
    "stopword_set = stopword_set.union({'это', 'который', 'весь', 'наш', 'свой', 'ещё', 'её', 'ваш', 'также', 'итак'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Идем в лемматизацию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = pymorphy3.MorphAnalyzer()\n",
    "\n",
    "@lru_cache(maxsize=10000)\n",
    "def get_lemma(word):\n",
    "    return lemmatizer.parse(word)[0].normal_form\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    text = ' '.join(text.split())\n",
    "    return text.lower()\n",
    "\n",
    "def is_pronoun_or_stopword(word):\n",
    "    return word in PRONOUNS or word in stopword_set\n",
    "\n",
    "def split_compound_words(word):\n",
    "    return re.findall(r'[А-Яа-яё]+', word)\n",
    "\n",
    "word_cache = {}\n",
    "\n",
    "def get_negative_words(text):\n",
    "    cleaned_text = clean_text(text)\n",
    "    print(cleaned_text)\n",
    "    negative_words = set()\n",
    "    mat_words = list(re.findall(mat_regex, cleaned_text, re.VERBOSE))\n",
    "    mat_words = set(split_compound_words(\"_\".join(mat_words)))\n",
    "    words = split_compound_words(text)\n",
    "    print(words)\n",
    "    for word in words:\n",
    "        if is_pronoun_or_stopword(word):\n",
    "            continue\n",
    "\n",
    "        if word in word_cache:\n",
    "            if word_cache[word] == 'NGTV':\n",
    "                negative_words.add(word)\n",
    "            continue\n",
    "\n",
    "        if word in mat_words:\n",
    "            word_cache[word] = \"NGTV\"\n",
    "            negative_words.add(word)\n",
    "            continue\n",
    "\n",
    "        if word == \"сука\":\n",
    "            word_cache[word] = \"NGTV\"\n",
    "            negative_words.add(word)\n",
    "            continue\n",
    "\n",
    "        lemma = get_lemma(word)\n",
    "        \n",
    "        if is_pronoun_or_stopword(lemma):\n",
    "            continue\n",
    "        \n",
    "        if lemma in term_to_tag_dict:\n",
    "            tag = term_to_tag_dict[lemma]\n",
    "            word_cache[word] = tag\n",
    "            if tag == 'NGTV':\n",
    "                negative_words.add(word)\n",
    "        else:\n",
    "            word_cache[word] = 'NEUT'\n",
    "    \n",
    "    return list(negative_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример работы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "который год - в стране царствует смута и развал, властвует произвол финансово- чиновничьей олигархии. который год мы ожидаем обещанного благополучия и процветания, получая взамен безудержный рост цен, неплатежи по зарплатам и социальным пособиям, межнациональные войны и конфликты, бандитизм и коррупцию. довольно слушать бесконечные обещания и заверения чиновников, терпеть унижения и издевательства обнаглевших \"реформаторов\". на попытку ельцина, с помощью отставки правительства, уйти от ответственности за содеянное - ответим решительным: ельцина - в отставку ! на попытку ельцина путем политических рокировок продлить агонию ненавистного антинародного режима - ответим : нет - антинародному курсу !на угрозы президента распустить государственную думу, выступающую за изменение курса \"реформ \", заявим: руки прочь от государственной думы! даешь правительство народного доверия!\n",
      "['Который', 'год', 'в', 'стране', 'царствует', 'смута', 'и', 'развал', 'властвует', 'произвол', 'финансово', 'чиновничьей', 'олигархии', 'Который', 'год', 'мы', 'ожидаем', 'обещанного', 'благополучия', 'и', 'процветания', 'получая', 'взамен', 'безудержный', 'рост', 'цен', 'неплатежи', 'по', 'зарплатам', 'и', 'социальным', 'пособиям', 'межнациональные', 'войны', 'и', 'конфликты', 'бандитизм', 'и', 'коррупцию', 'Довольно', 'слушать', 'бесконечные', 'обещания', 'и', 'заверения', 'чиновников', 'терпеть', 'унижения', 'и', 'издевательства', 'обнаглевших', 'реформаторов', 'На', 'попытку', 'Ельцина', 'с', 'помощью', 'отставки', 'правительства', 'уйти', 'от', 'ответственности', 'за', 'содеянное', 'ответим', 'решительным', 'Ельцина', 'в', 'отставку', 'На', 'попытку', 'Ельцина', 'путем', 'политических', 'рокировок', 'продлить', 'агонию', 'ненавистного', 'антинародного', 'режима', 'ответим', 'НЕТ', 'антинародному', 'курсу', 'На', 'угрозы', 'президента', 'распустить', 'Государственную', 'Думу', 'выступающую', 'за', 'изменение', 'курса', 'реформ', 'заявим', 'Руки', 'прочь', 'от', 'Государственной', 'Думы', 'Даешь', 'Правительство', 'народного', 'доверия']\n",
      "Негативные слова: ['антинародного', 'чиновничьей', 'неплатежи', 'смута', 'олигархии', 'издевательства', 'произвол', 'развал', 'антинародному', 'унижения', 'агонию', 'войны', 'бандитизм', 'обнаглевших', 'отставку', 'угрозы', 'властвует', 'коррупцию', 'ненавистного', 'терпеть', 'конфликты', 'отставки']\n"
     ]
    }
   ],
   "source": [
    "text = '''Который год - в стране царствует смута и развал, властвует произвол финансово- чиновничьей олигархии.\n",
    "Который год мы ожидаем обещанного благополучия и процветания, получая взамен безудержный рост цен, неплатежи по зарплатам и социальным пособиям, межнациональные войны и конфликты, бандитизм и коррупцию.\n",
    "Довольно слушать бесконечные обещания и заверения чиновников, терпеть унижения и издевательства обнаглевших \"реформаторов\".\n",
    "На попытку Ельцина, с помощью отставки правительства, уйти от ответственности за содеянное - ответим решительным: Ельцина - в отставку !\n",
    "На попытку Ельцина путем политических рокировок продлить агонию ненавистного антинародного режима - ответим : НЕТ - антинародному курсу !На угрозы президента распустить Государственную Думу, выступающую за изменение курса \"реформ \", заявим: Руки прочь от Государственной Думы! Даешь Правительство народного доверия!'''\n",
    "negative_words = get_negative_words(text)\n",
    "print(\"Негативные слова:\", negative_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Исправление ошибок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CORRECT</th>\n",
       "      <th>MISTAKE</th>\n",
       "      <th>WEIGHT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>болота</td>\n",
       "      <td>балото</td>\n",
       "      <td>0.2652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>болота</td>\n",
       "      <td>боллото</td>\n",
       "      <td>0.0909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>болота</td>\n",
       "      <td>болотоэ</td>\n",
       "      <td>0.0909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>болото</td>\n",
       "      <td>палатаа</td>\n",
       "      <td>0.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>болото</td>\n",
       "      <td>болотл</td>\n",
       "      <td>0.3333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  CORRECT  MISTAKE  WEIGHT\n",
       "1  болота   балото  0.2652\n",
       "2  болота  боллото  0.0909\n",
       "3  болота  болотоэ  0.0909\n",
       "4  болото  палатаа  0.5000\n",
       "5  болото   болотл  0.3333"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors_dataset = pd.read_csv(\"/Users/a.chervonikov/Desktop/Purify/Purify/purify_ml/data/raw/orfo_and_typos.L1_5+PHON.csv\", sep = \";\").iloc[1:, :]\n",
    "# errors_dataset['weight'] = errors_dataset['weight'].apply(lambda x: '{0:.15f}'.format(float(x)))\n",
    "errors_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>correct</th>\n",
       "      <th>error</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [correct, error, weight]\n",
       "Index: []"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string_weights = errors_dataset[~errors_dataset['weight'].apply(lambda x: str(x).replace('.', '').isdigit())]\n",
    "string_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 90972 entries, 1 to 90972\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   correct  90972 non-null  object\n",
      " 1   error    90972 non-null  object\n",
      " 2   weight   90972 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 2.1+ MB\n"
     ]
    }
   ],
   "source": [
    "errors_dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.024075031280517578\n",
      "None\n",
      "0.02206707000732422\n",
      "9.5367431640625e-07\n",
      "0.024689197540283203\n",
      "0.024259090423583984\n",
      "Это местный текст с ашибками и опечатками некрасиво.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import re\n",
    "from Levenshtein import distance as levenshtein_distance\n",
    "from functools import lru_cache\n",
    "\n",
    "class SpellChecker:\n",
    "    def __init__(self, dataset_path, max_distance=2):\n",
    "        self.correct_words = set()\n",
    "        self.error_to_correct = defaultdict(list)\n",
    "        self.max_distance = max_distance\n",
    "        \n",
    "        df = pd.read_csv(dataset_path, sep=';', header=None, \n",
    "                        names=['correct', 'error', 'weight']).iloc[1:, :]\n",
    "        \n",
    "        for _, row in df.iterrows():\n",
    "            correct = row['correct'].strip().lower()\n",
    "            error = row['error'].strip().lower()\n",
    "            weight = float(row['weight'])\n",
    "            \n",
    "            self.correct_words.add(correct)\n",
    "            self.error_to_correct[error].append((correct, weight))\n",
    "        \n",
    "        for error in self.error_to_correct:\n",
    "            self.error_to_correct[error].sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        self.all_known_words = list(self.correct_words) + list(self.error_to_correct.keys())\n",
    "    \n",
    "    @lru_cache(maxsize=10000)\n",
    "    def find_closest_word(self, word):\n",
    "        if not word:\n",
    "            return None\n",
    "            \n",
    "        word = word.lower()\n",
    "        \n",
    "        if word in self.correct_words:\n",
    "            return word\n",
    "        if word in self.error_to_correct:\n",
    "            return self.error_to_correct[word][0][0]\n",
    "        \n",
    "        min_distance = float('inf')\n",
    "        closest_word = None\n",
    "        \n",
    "        for known_word in self.all_known_words:\n",
    "            current_distance = levenshtein_distance(word, known_word)\n",
    "            if current_distance < min_distance and current_distance <= self.max_distance:\n",
    "                min_distance = current_distance\n",
    "                closest_word = known_word\n",
    "        \n",
    "        return closest_word\n",
    "    \n",
    "    def correct_spelling(self, word):\n",
    "        word = word.lower().strip()\n",
    "        \n",
    "        if hasattr(self, '_spelling_cache') and word in self._spelling_cache:\n",
    "            return self._spelling_cache[word]\n",
    "        \n",
    "        if word in self.correct_words:\n",
    "            return word\n",
    "        \n",
    "        if word in self.error_to_correct:\n",
    "            correction = self.error_to_correct[word][0][0]\n",
    "            if not hasattr(self, '_spelling_cache'):\n",
    "                self._spelling_cache = {}\n",
    "            self._spelling_cache[word] = correction\n",
    "            return correction\n",
    "        \n",
    "        import time\n",
    "        start = time.time()\n",
    "        closest_word = self.find_closest_word(word)\n",
    "        end = time.time()\n",
    "        print(f\"{end - start}\")\n",
    "        if closest_word:\n",
    "            if closest_word in self.error_to_correct:\n",
    "                correction = self.error_to_correct[closest_word][0][0]\n",
    "            else:\n",
    "                correction = closest_word\n",
    "            \n",
    "            if not hasattr(self, '_spelling_cache'):\n",
    "                self._spelling_cache = {}\n",
    "            self._spelling_cache[word] = correction\n",
    "            return correction\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def correct_text(self, text):\n",
    "        tokens = re.findall(r\"(\\w+|\\W+)\", text)\n",
    "        corrected_tokens = []\n",
    "        for token in tokens:\n",
    "            if token.strip() and token[0].isalpha():  \n",
    "                correction = self.correct_spelling(token)\n",
    "                if correction is not None:\n",
    "                    if token[0].isupper():\n",
    "                        correction = correction.capitalize()\n",
    "                    corrected_tokens.append(correction)\n",
    "                else:\n",
    "                    corrected_tokens.append(token)\n",
    "            else:\n",
    "                corrected_tokens.append(token)\n",
    "        \n",
    "        return ''.join(corrected_tokens)\n",
    "\n",
    "checker = SpellChecker(\"/Users/a.chervonikov/Desktop/Purify/Purify/purify_ml/data/raw/orfo_and_typos.L1_5+PHON.csv\")\n",
    "print(checker.correct_spelling(\"ашибками\"))\n",
    "text = \"Это тествый текст с ашибками и опечатками некрасыво.\"\n",
    "print(checker.correct_text(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "местный\n"
     ]
    }
   ],
   "source": [
    "print(checker.correct_spelling(\"тествый\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      "Ты тупкя!\n"
     ]
    }
   ],
   "source": [
    "print(checker.correct_spelling(\"туптй\"))  \n",
    "print(checker.correct_spelling(\"несуществующееслово\"))  \n",
    "text = \"Ты тупкя!\"\n",
    "\n",
    "corrected = checker.correct_text(text)\n",
    "print(corrected)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
